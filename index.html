
<!DOCTYPE html>
<!-- Thanks to url=https://www.aicitychallenge.org/ -->
<!-- TODO: -->
<!--  complete WORKSHOP pages -->


<html lang="en-US" class="js svg background-fixed">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CRDH â€“ 2020 IEEE AIVR WORKSHOP</title>
  <script src="https://www.w3schools.com/lib/w3.js"></script> 

  <link rel="profile" href="http://gmpg.org/xfn/11">
  <link rel="dns-prefetch" href="https://fonts.googleapis.com/">
  <link rel="dns-prefetch" href="https://s.w.org/">
  <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="">
  <link rel="stylesheet" id="wp-quicklatex-format-css" href="css/quicklatex-format.css" media="all">
  <link rel="stylesheet" id="sdm-styles-css" href="css/sdm_wp_styles.css" media="all">
  <link rel="stylesheet" id="uaf_client_css-css" href="css/uaf.css" media="all">
  <link rel="stylesheet" id="twentyseventeen-fonts-css" href="css/font_latin.css" media="all">
  <link rel="stylesheet" id="twentyseventeen-style-css" href="css/style.css" media="all">
  <link rel="stylesheet" id="font-awesome-css" href="css/font-awesome.min.css" media="all">
  <link rel="stylesheet" id="elementor-animations-css" href="css/animations.min.css" media="all">
  <link rel="stylesheet" id="elementor-frontend-css" href="css/frontend.min.css" media="all">
  <link rel="stylesheet" id="elementor-global-css" href="css/global.css" media="all">
  <link rel="stylesheet" id="elementor-icons-css" href="css/elementor-icons.min.css" media="all">
  <link rel="stylesheet" id="elementor-post-11-css" href="css/post-11.css" media="all">
  <link rel="stylesheet" id="google-fonts-1-css" href="css/font_cy.css" media="all">

</head>

<body class="twentyseventeen-front-page has-header-video">

<div id="HOME" class="centerContainer">
  <!-- header -->
  <header id="header" class="site-header" role="banner">

    <div class="custom-header" style="margin-bottom: 72px;">

      <!-- Video -->
      <!-- e3r-gVIf-qc.mp4, QYDY_8lL89E.mp4 -->
      <!-- https://developers.google.com/youtube/player_parameters -->
      <div class="custom-header-media">
        <div id="myvideo">
  <img class="trailer" src="img/slideshow/realistic_1.jpg">
  <img class="trailer" src="img/slideshow/realistic_2.jpg">
  <img class="trailer" src="img/slideshow/realistic_3.jpg">
  <img class="trailer" src="img/slideshow/realistic_4.jpg">
  <img class="trailer" src="img/slideshow/interdigital.jpg">
  <img class="trailer" src="img/slideshow/interdigital-2.jpg">
  <img class="trailer" src="img/slideshow/interdigital-3.jpg">
  <script>
	w3.slideshow(".trailer", 3000);
  </script>
</div>
      </div>

      <div class="site-branding">
        <div class="wrap">
          <h1 class="site-title"><a href="#INTRODUCTION" rel="home">CRDH : From Capture to Rendering of Digital Humans for AR/VR</a></h1>
          <p class="site-description">December 14-16 @ 3rd IEEE International Conference on AIVR 2020 in Utrecht, The Netherlands.</p>
        </div><!-- .wrap -->
      </div><!-- .site-branding -->

    </div><!-- .custom-header -->

    <div class="navigation-top">
      <div class="wrap">
        <nav id="site-navigation" class="main-navigation">

          <!-- Floating menu -->
          <button class="menu-toggle">
            Menu
          </button>

          <ul id="top-menu" class="menu">
            <li id="homeitem" class="menu-item"><a href="#HOME">HOME</a></li>
            <li id="introductionitem" class="menu-item"><a href="#INTRODUCTION">INTRODUCTION</a></li>
            <li id="newsitem" class="menu-item"><a href="#NEWS">NEWS</a></li>
            <li id="locationsitem" class="menu-item"><a href="#LOCATION">LOCATION</a></li>
            <li id="papersitem" class="menu-item"><a href="#SUBMISSION">SUBMISSION</a></li>
            <li id="rightsitem" class="menu-item"><a href="#RIGHTS">RIGHTS</a></li>
            <li id="workshopitem" class="menu-item"><a href="#WORKSHOPPROGRAM">PROGRAM</a></li>
            <li id="datesitem" class="menu-item"><a href="#IMPORTANTDATES">DATES</a></li>
            <!--
            <li id="posteritem" class="menu-item"><a href="#POSTERS">POSTERS</a></li>
            -->

            <li id="submenu" class="menu-item-has-children">
              <a>INFO</a>
              <ul class="sub-menu">
                <li id="speakersitem" class="menu-item"><a href="#INVITEDSPEAKERS">Invited Speakers</a></li>
                <li id="committeeitem" class="menu-item"><a href="#ORGANIZINGCOMMITTEES">Organizers</a>
                </li>
                <li id="contactitem" class="menu-item"><a href="#CONTACT">Contact Us</a></li>
              </ul>
            </li>

          </ul>

        </nav><!-- #site-navigation -->
      </div><!-- .wrap -->
    </div><!-- .navigation-top -->

  </header><!-- #masthead -->

  <!-- content -->
  <div class="site-content-contain">
<!--    style="background-image: url('img/background.png');-->
<!--			background-attachment: scroll; background-size: 100%; background-repeat: repeat-y; background-position:-->
<!--			center;">-->
    <div class="elementor elementor-11" style="margin: 0 5% 0 5%">

      <!-- Introduction -->
      <div>
        <div>
          <h2 id="INTRODUCTION" class="elementor-heading-title">
            INTRODUCTION</h2>
        </div>
        <div class="elementor-widget-text-editor">
          <div class="elementor-text-editor">
            Realistic representation of digital humans in AR/VR applications is only made possible with the capture of high-quality data and appropriate rendering techniques. 
	   While capturing of accurate and relightable data is required to produce assets for realistic avatars, we also need real-time performance capture to ensure success of applications like teleconference and teleportation.
	   On the other side, rendering of photo-real humans is even more important to the immersive experience in virtual scenes. This workshop provides a platform to share some of the most advanced human face/body capturing systems from pore-level high resolution capture to rapid motion capture along with the art of data processing. 
	   It will also cover novel rendering along with environment lighting estimation techniques required in AR/VR, like neural rendering.
			
            <br><br>
            We expect that the workshop will inspire novel ideas based on current practices in the field of rendering realistic digital humans and accelerate the hardware and software development in the same field.
			
            A major goal of this workshop will be to bring researchers potential collaboration opportunities. It will also provide a good introduction for researchers that are interested and want to start their
            research in the field.

            <br><br>
          </div>
        </div>
      </div>
      
      <!-- NEWS -->
      <div>
        <div>
          <h2 id="NEWS" class="elementor-heading-title">
            NEWS</h2>
        </div>
        <div class="elementor-widget-text-editor">
          <div class="elementor-text-editor">
            Website for the edition 2020 is online!
            <br><br>
          </div>
        </div>
      </div>
      
      <!-- Location -->
      <div>
        <div>
          <h2 id="LOCATION" class="elementor-heading-title">
            LOCATION</h2>
        </div>
        <div class="elementor-widget-text-editor">
          <div class="elementor-text-editor">
            The workshop will take place during the IEEE 3rd International Conference on Artificial Intelligence & Virtual Reality (AIVR 2020).
            Check the <b><a
              href="http://aivr.science.uu.nl/" target="_blank">conference website</a></b> for relevant information 

            <br><br>
          </div>
        </div>
      </div>

      <!-- Call for Papers -->
      <div>
        <div>
          <h2 id="SUBMISSION" class="elementor-heading-title">SUBMISSION</h2>
        </div>


        <div class="elementor-widget-text-editor">
          <div>
            Authors are invited to submit a maximum <b>4 pages</b> technical workshop paper in double-column IEEE format following the official <b><a
              href="https://www.ieee.org/conferences/publishing/templates.html"
              target="_blank">IEEE Manuscript Formatting guidelines.</a></b>
			All submissions will go through a double-blind peer-review process. Authors of accepted papers are expected to attend the conference and present their paper at the workshop.
  

            <br><br>

           <!-- All the papers should be submitted using CMT website: <a
              href="https://cmt3.research.microsoft.com/360PI2019/" target="_blank">https://cmt3.research.microsoft.com/360PI2019/</a>. -->
          <!--  Please email your submissions to <b>cdrh_workshop@gmx.com</b> with [Workshop CRDH] in the subject line. In case of questions, you can also send an email to the workshop organizers (see below). -->
            <b>All the papers should be submitted using <u>EasyChair website</u> under the track of <i>"IEEE AIVR 2020 - Workshop on From Capture to Rendering of Digital Humans for AR/VR" (online soon !).</i></b>
		  <br><br>


            The topic should includes but not limited to:

            <br><br>

            <div style="margin: 0 50px">
              <ul>
                <li>Capture systems (hardware / software)</li>
                <li>Creation of Digital Humans</li>
                <li>Rendering of Digital Humans</li>
                <li>Motion capture</li>
                <li>AR/VR experience with Digital Humans</li>
                <li>Anything related to Digital Humans</li>
              </ul>
            </div>

          </div>
        </div>
      </div>
      Accepted workshop papers and special session papers will be published in the conference proceedings by IEEE Computer Society Press and included in the IEEE Xplore Digital Library.
      <br><br>
	  
	  
	  <!-- Rights -->
      <div>
        <div>
          <h2 id="RIGHTS="elementor-heading-title">RIGHTS</h2>
        </div>
        <div class="elementor-widget-text-editor">
          <div class="elementor-text-editor">
            The work submitted to the conference is subject to the <b><a
              href="https://www.ieee.org/publications/rights/index.html"
              target="_blank">IEEE Intellectual Property Rights</a></b> and  <b><a
              href="https://www.ieee.org/publications/rights/copyright-policy.html"
              target="_blank">Copyright policy</a></b>.
            Please read carefully the linked webpages before submitting a contribution.
            <br><br>
          </div>
        </div>
      </div>
      
	  <!-- Important Dates -->
      <div>
        <div>
          <h2 id="IMPORTANTDATES" class="elementor-heading-title">IMPORTANT DATES</h2>
        </div>

        <div class="elementor-widget-text-editor">
          <div style="text-align: center">
            <table class="tg">
              <tr>
                <td>Paper submission deadline:</td>
                <td><b>September 24<sup>th</sup>, 2020</b>
                </td>
              </tr>
              <tr>
                <td>Notification of acceptance:</td>
                <td><b>October 16<sup>th</sup>, 2020</b></td>
              </tr>
              <tr>
                <td>Camera-ready Deadline:</td>
                <td><b>October 30<sup>th</sup>, 2020</b></td>
              </tr>
              <tr>
                <td>Workshop date:</td>
                <td><b>December 14<sup>th</sup>, 2020
               </b></td>
              </tr>
            </table>
          </div>
        </div>
      </div>

      <!-- Workshop Program -->
      <div>
        <div class="elementor-widget-container">
          <h2 id="WORKSHOPPROGRAM" class="elementor-heading-title elementor-size-default">
            WORKSHOP PROGRAM</h2>
        </div>
	<div class="elementor-widget-text-editor">
          <div class="elementor-text-editor">
            <b>TBD</b> <br /> The program of the previous edition can be found on the <a href="https://aivr2019.github.io/CRDH-workshop/">CRDH 2019 website</a>
            <br><br>
          </div>

          <!-- <b>Workshop Date: December 9, 2019</b>
		   <br><br>
							  
	 <b>14:00 - 15:45 Session 4B: Workshop CRHD (part 1)</b>
             <div style="margin: 0 50px">
              <ul>
              
                <li>14:00 - 14:10 Introduction</li>
                <li>14:10 - 14:55 Keynote Speaker:Ari Shapiro</li>
                <li>14:55 - 15:20 Invited Paper:Temporal Interpolation of Dynamic Digital Humans(<b>Irene Viola, Jelmer Mulder, Francesca De Simone and Pablo Cesar</b>)</li>
                <li>15:20 - 15:45 Invited Talk:Fabien Danieau</li> 
	      </ul>
            </div>
					
          <b>15:45 - 16:15 Coffee Break</b> 
	    <br/> <br/>
          <b>16:15-18:00 Session 5B: Workshop CRHD (part 2)</b>       
	<div style="margin: 0 50px">
              <ul>
		<li>16:15 - 16:45 Invited Talk:Chloe Legendre</li>
                <li>16:45 - 17:00 Paper:Influence of Motion Speed on the Perception of Latency in Avatar Control(<b>Ludovic Hoyet, ClÃ©ment Spies, Pierre Plantard, Anthony Sorel, Richard Kulpa and Franck Multon</b>).</li>
                <li>17:00 - 17:15 Paper:The Design Process for Enhancing Visual Expressive Qualities of Characters from Performance Capture into Virtual Reality(<b>Victoria Campbell</b>)</li>
                <li>17:15 - 17:45 Invited Talk:Kalle Bladin</li>
                <li>17:45 - 18:00 Wrap up</li>
               </ul> -->
            </div>						  
       </div>
       
         <!-- Invited Speakers -->
      <div>
        <div>
          <h2 id="INVITEDSPEAKER" class="elementor-heading-title">INVITED SPEAKERS</h2>
        </div>

        <div class="elementor-widget-text-editor">
          <div class="elementor-text-editor">
            <b>To be announced</b>
            <br><br>
          </div>

         <!-- <div style="text-align: left">
            <table class="tg">
              <tr>
               <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="http://www.arishapiro.com/" target="_blank">
                   <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px; max-width: 150px;border-radius: 50%;"
                           src="img/ariShapiro2.jpg" alt=""> 
					
                 </div></td>
                <td><b>Ari Shapiro</b><br/>
							  <b>Title:</b>Digital humans: models of behavior and interactivity<br/>
							  <b>Abstract:</b>As techniques for capturing and generating realistic digital humans become more widely available, the need for realistic movement and behavior becomes more important. The Uncanny Valley effect is more pronounced for moving, as opposed to still, imagery, necessitating higher fidelity motion replication, such as from motion capture, as well as higher fidelity behavior models for synthetic movement. This talk explores my work in modeling both appearance and behavior of digital humans, including capture, rigging, and interactivity.<br/>
                </td>
              </tr>
                  <tr>
               <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="http://chloelegendre.com/" target="_blank">
                   <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px; max-width: 150px;border-radius: 50%;"
                           src="img/chloe.png" alt=""> 
					
                 </div></td>
                <td><b>Chloe LeGendre</b><br/>
							  <b>Title:</b>Multispectral Illumination in USC ICT's Light Stage X<br/>
							  <b>Abstract:</b>USC ICT's computational illumination system Light Stage X has been used for a variety of different techniques: from studio lighting reproduction to high resolution facial scanning. In this talk, I'll describe how adding multispectral LEDs to the system has improved color rendition for a variety of such Light Stage techniques, while also enabling higher resolution facial capture. I will conclude with opportunities for future work on human digitization leveraging multispectral illumination sources.<br/>
                </td>
              </tr>
                   <tr>
               <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="http://kbladin.se/about/" target="_blank">
                   <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px; max-width: 150px;border-radius: 50%;"
                           src="img/Kalle.jpg" alt=""> 
					
                 </div></td>
                <td><b>Kalle Bladin</b><br/>
							  <b>Title:</b>Automating mass production of digital avatars for VR<br/>
							  <b>Abstract:</b>This talk covers how the Vision and Graphics Lab at USCâ€™s ICT is leveraging the latest Light Stage technology to devise a database of facial scans. Recent movements toward a convergence of visual quality in real time and offline rendering, in conjunction with the massive rise of deep learning approaches for processing and recreation of human data, have drastically simplified the ability to generate realistic avatars for VR; something that previously was reserved to high end visual effects studios requiring a multitude of highly specialized artists and engineers. We have developed a pipeline for scanning, preprocessing, and registration of expressive facial scans to automate the building of a database that enables training of machine learning algorithms to generate highly detailed and visually realistic avatars. This presentation will focus on the main obstacles confronted when building such a database and pipeline, aimed specifically for facial scan data but stretching further by combining multiple data sources and providing automatic rigging, animation, and rendering of a massive number of digital avatars.<br/>
                </td>
              </tr>
               <tr>
               <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="http://fdanieau.free.fr/" target="_blank">
                   <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px; max-width: 150px;border-radius: 50%;"
                           src="img/fabien_danieau.jpg" alt=""> 
					
                 </div></td>
                <td><b>Fabien Danieau</b><br/>
							  <b>Title:</b>Automatic Generation of 3D Facial Rigs<br/>
							  <b>Abstract:</b>Digital humans are key aspects of the rapidly evolving areas of virtual reality, augmented reality, virtual production and gaming. Even outside of the entertainment world, they are becoming more and more commonplace in retail, sports, social media, education, health and many other fields. This talk presents a fully automatic pipeline for generating and high geometric and textural quality facial rigs. They are automatically rigged with facial blendshapes for animation. The steps of this pipeline such as photogrammetry, landmarking, retopology, and blenshapes transfer are detailed. Then two applications for creating fast VR avatars, and for generating quality digital doubles are showcased.<br/>
                </td>
              </tr>
            </table>
          </div>-->
        </div>
      </div>
			     
			     
			     
      <!-- Organizing Committee -->
      <div>

        <div>
          <h2 id="ORGANIZINGCOMMITTEES" class="elementor-heading-title">ORGANIZERS</h2>
        </div>

        <div class="elementor-widget-text-editor">
          <table class="tg">
            <tr>

              <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="https://www.yajie-zhao.com/" target="_blank">
                   <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px; max-width: 150px;border-radius: 50%;"
                           src="img/yajie.jpg" alt=""> 
					
                 </div>

                    <div class="elementor-image-box-content">
                      <h3 class="elementor-image-box-title">Yajie Zhao</h3>
                      <p class="elementor-image-box-description">USC Institute for Creative Technologies,USA</p>
                    </div>
                  </a>
                </div>
              </td>
			  
			  <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="http://fdanieau.free.fr/" target="_blank">
                    <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px;max-width: 150px;border-radius: 50%;"
                           src="img/fabien_danieau.jpg" alt="">
                    </div>

                    <div class="elementor-image-box-content">
                      <h3 class="elementor-image-box-title">Fabien Danieau</h3>
                      <p class="elementor-image-box-description">InterDigital, France</p>
                    </div>
                  </a>

                </div>
              </td>

              <td class="elementor-widget-image-box">
                <div class="elementor-image-box-wrapper">

                  <a href="https://stevetonneau.fr/" target="_blank">
                    <div class="elementor-image-box-img">
                      <img style="margin: auto; height: 150px;max-width: 150px;border-radius: 50%;"
                           src="img/stevetonneau.png" alt="">
                    </div>

                    <div class="elementor-image-box-content">
                      <h3 class="elementor-image-box-title">Steve Tonneau</h3>
                      <p class="elementor-image-box-description">University of Edinburgh, UK </p>
                    </div>
                  </a>

                </div>
              </td>

              

            </tr>
            <tr>

   
            </tr>
          </table>
        </div>
      </div>


      <!-- Contact Us -->
      <div>

        <div>
          <h2 id="CONTACT" class="elementor-heading-title">CONTACT US</h2>
        </div>
		 <div class="elementor-widget-text-editor">
           If you have any questions, please contact <b>Yajie Zhao</b> (zhao[at].ict.usc.edu), or <b>Fabien Danieau</b> (fabien.danieau[at]interdigital.com)
		   or <b>Steve Tonneau</b> (stonneau[at]ed.ac.uk).
		   <br><br>
       </div>
      
      </div>

    </div>

    <!-- footer -->
    <footer id="colophon" class="site-footer" role="contentinfo">
      <div class="wrap">

        <div class="widget-column footer-widget-1">
          <div class="textwidget"><p>CRDH Workshop - IEEE AIVR 2020</p>
          </div>
        </div>
    

      </div><!-- .wrap -->

    </footer><!-- #colophon -->

  </div><!-- .site-content-contain -->
</div><!-- #page -->

<script src="js/skip-link-focus-fix.js"></script>
<script src="js/navigation.js"></script>
<script src="js/global.js"></script>
<script src="js/jquery.scrollTo.js"></script>
<script src="js/wp-embed.min.js"></script>
<script src="js/wp-a11y.min.js"></script>
<script src="js/wp-custom-header.min.js"></script>
<script src="js/position.min.js"></script>
<script src="js/dialog.min.js"></script>
<script src="js/waypoints.min.js"></script>
<script src="js/swiper.jquery.min.js"></script>
<script src="js/frontend.min.js"></script>

</body>
</html>
